{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "298b4e79-1451-4f4e-8814-f3aca4c29f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "8f99d59d-eafc-4b02-a7cd-50fad544a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "4ca6e86d-29aa-42bb-9ad0-47690efb4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['area','bedrooms', 'bathrooms']].values\n",
    "y = data['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "d9ad2dfb-8e2d-44f8-8c13-c55e94833ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7420,    4,    2],\n",
       "       [8960,    4,    4],\n",
       "       [9960,    3,    2],\n",
       "       ...,\n",
       "       [3620,    2,    1],\n",
       "       [2910,    3,    1],\n",
       "       [3850,    3,    1]], dtype=int64)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "cc248aed-0fbe-49b0-8c97-27ef4fd7c226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13300000, 12250000, 12250000, 12215000, 11410000, 10850000,\n",
       "       10150000, 10150000,  9870000,  9800000,  9800000,  9681000,\n",
       "        9310000,  9240000,  9240000,  9100000,  9100000,  8960000,\n",
       "        8890000,  8855000,  8750000,  8680000,  8645000,  8645000,\n",
       "        8575000,  8540000,  8463000,  8400000,  8400000,  8400000,\n",
       "        8400000,  8400000,  8295000,  8190000,  8120000,  8080940,\n",
       "        8043000,  7980000,  7962500,  7910000,  7875000,  7840000,\n",
       "        7700000,  7700000,  7560000,  7560000,  7525000,  7490000,\n",
       "        7455000,  7420000,  7420000,  7420000,  7350000,  7350000,\n",
       "        7350000,  7350000,  7343000,  7245000,  7210000,  7210000,\n",
       "        7140000,  7070000,  7070000,  7035000,  7000000,  6930000,\n",
       "        6930000,  6895000,  6860000,  6790000,  6790000,  6755000,\n",
       "        6720000,  6685000,  6650000,  6650000,  6650000,  6650000,\n",
       "        6650000,  6650000,  6629000,  6615000,  6615000,  6580000,\n",
       "        6510000,  6510000,  6510000,  6475000,  6475000,  6440000,\n",
       "        6440000,  6419000,  6405000,  6300000,  6300000,  6300000,\n",
       "        6300000,  6300000,  6293000,  6265000,  6230000,  6230000,\n",
       "        6195000,  6195000,  6195000,  6160000,  6160000,  6125000,\n",
       "        6107500,  6090000,  6090000,  6090000,  6083000,  6083000,\n",
       "        6020000,  6020000,  6020000,  5950000,  5950000,  5950000,\n",
       "        5950000,  5950000,  5950000,  5950000,  5950000,  5943000,\n",
       "        5880000,  5880000,  5873000,  5873000,  5866000,  5810000,\n",
       "        5810000,  5810000,  5803000,  5775000,  5740000,  5740000,\n",
       "        5740000,  5740000,  5740000,  5652500,  5600000,  5600000,\n",
       "        5600000,  5600000,  5600000,  5600000,  5600000,  5600000,\n",
       "        5600000,  5565000,  5565000,  5530000,  5530000,  5530000,\n",
       "        5523000,  5495000,  5495000,  5460000,  5460000,  5460000,\n",
       "        5460000,  5425000,  5390000,  5383000,  5320000,  5285000,\n",
       "        5250000,  5250000,  5250000,  5250000,  5250000,  5250000,\n",
       "        5250000,  5250000,  5250000,  5243000,  5229000,  5215000,\n",
       "        5215000,  5215000,  5145000,  5145000,  5110000,  5110000,\n",
       "        5110000,  5110000,  5075000,  5040000,  5040000,  5040000,\n",
       "        5040000,  5033000,  5005000,  4970000,  4970000,  4956000,\n",
       "        4935000,  4907000,  4900000,  4900000,  4900000,  4900000,\n",
       "        4900000,  4900000,  4900000,  4900000,  4900000,  4900000,\n",
       "        4900000,  4900000,  4893000,  4893000,  4865000,  4830000,\n",
       "        4830000,  4830000,  4830000,  4795000,  4795000,  4767000,\n",
       "        4760000,  4760000,  4760000,  4753000,  4690000,  4690000,\n",
       "        4690000,  4690000,  4690000,  4690000,  4655000,  4620000,\n",
       "        4620000,  4620000,  4620000,  4620000,  4613000,  4585000,\n",
       "        4585000,  4550000,  4550000,  4550000,  4550000,  4550000,\n",
       "        4550000,  4550000,  4543000,  4543000,  4515000,  4515000,\n",
       "        4515000,  4515000,  4480000,  4480000,  4480000,  4480000,\n",
       "        4480000,  4473000,  4473000,  4473000,  4445000,  4410000,\n",
       "        4410000,  4403000,  4403000,  4403000,  4382000,  4375000,\n",
       "        4340000,  4340000,  4340000,  4340000,  4340000,  4319000,\n",
       "        4305000,  4305000,  4277000,  4270000,  4270000,  4270000,\n",
       "        4270000,  4270000,  4270000,  4235000,  4235000,  4200000,\n",
       "        4200000,  4200000,  4200000,  4200000,  4200000,  4200000,\n",
       "        4200000,  4200000,  4200000,  4200000,  4200000,  4200000,\n",
       "        4200000,  4200000,  4200000,  4200000,  4193000,  4193000,\n",
       "        4165000,  4165000,  4165000,  4130000,  4130000,  4123000,\n",
       "        4098500,  4095000,  4095000,  4095000,  4060000,  4060000,\n",
       "        4060000,  4060000,  4060000,  4025000,  4025000,  4025000,\n",
       "        4007500,  4007500,  3990000,  3990000,  3990000,  3990000,\n",
       "        3990000,  3920000,  3920000,  3920000,  3920000,  3920000,\n",
       "        3920000,  3920000,  3885000,  3885000,  3850000,  3850000,\n",
       "        3850000,  3850000,  3850000,  3850000,  3850000,  3836000,\n",
       "        3815000,  3780000,  3780000,  3780000,  3780000,  3780000,\n",
       "        3780000,  3773000,  3773000,  3773000,  3745000,  3710000,\n",
       "        3710000,  3710000,  3710000,  3710000,  3703000,  3703000,\n",
       "        3675000,  3675000,  3675000,  3675000,  3640000,  3640000,\n",
       "        3640000,  3640000,  3640000,  3640000,  3640000,  3640000,\n",
       "        3640000,  3633000,  3605000,  3605000,  3570000,  3570000,\n",
       "        3570000,  3570000,  3535000,  3500000,  3500000,  3500000,\n",
       "        3500000,  3500000,  3500000,  3500000,  3500000,  3500000,\n",
       "        3500000,  3500000,  3500000,  3500000,  3500000,  3500000,\n",
       "        3500000,  3500000,  3493000,  3465000,  3465000,  3465000,\n",
       "        3430000,  3430000,  3430000,  3430000,  3430000,  3430000,\n",
       "        3423000,  3395000,  3395000,  3395000,  3360000,  3360000,\n",
       "        3360000,  3360000,  3360000,  3360000,  3360000,  3360000,\n",
       "        3353000,  3332000,  3325000,  3325000,  3290000,  3290000,\n",
       "        3290000,  3290000,  3290000,  3290000,  3290000,  3290000,\n",
       "        3255000,  3255000,  3234000,  3220000,  3220000,  3220000,\n",
       "        3220000,  3150000,  3150000,  3150000,  3150000,  3150000,\n",
       "        3150000,  3150000,  3150000,  3150000,  3143000,  3129000,\n",
       "        3118850,  3115000,  3115000,  3115000,  3087000,  3080000,\n",
       "        3080000,  3080000,  3080000,  3045000,  3010000,  3010000,\n",
       "        3010000,  3010000,  3010000,  3010000,  3010000,  3003000,\n",
       "        2975000,  2961000,  2940000,  2940000,  2940000,  2940000,\n",
       "        2940000,  2940000,  2940000,  2940000,  2870000,  2870000,\n",
       "        2870000,  2870000,  2852500,  2835000,  2835000,  2835000,\n",
       "        2800000,  2800000,  2730000,  2730000,  2695000,  2660000,\n",
       "        2660000,  2660000,  2660000,  2660000,  2660000,  2660000,\n",
       "        2653000,  2653000,  2604000,  2590000,  2590000,  2590000,\n",
       "        2520000,  2520000,  2520000,  2485000,  2485000,  2450000,\n",
       "        2450000,  2450000,  2450000,  2450000,  2450000,  2408000,\n",
       "        2380000,  2380000,  2380000,  2345000,  2310000,  2275000,\n",
       "        2275000,  2275000,  2240000,  2233000,  2135000,  2100000,\n",
       "        2100000,  2100000,  1960000,  1890000,  1890000,  1855000,\n",
       "        1820000,  1767150,  1750000,  1750000,  1750000], dtype=int64)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "71de2f94-bccc-4c79-a7fa-f60b555d9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return (X - mean) / std, mean, std\n",
    "\n",
    "X_norm, X_mean, X_std = normalize_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "6c2ab154-e868-4070-a01e-dcb9103bbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "5a5b59e1-138e-4df3-9b9c-98baf36c7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w):\n",
    "    m = len(y)\n",
    "    predictions = hypothesis(X, w)\n",
    "    cost = (1/(2*m)) * np.sum((predictions - y) ** 2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "63e6f9e1-408b-4470-a451-3cea0df71bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_step(X, y, w, learning_rate):\n",
    "    m = len(y)\n",
    "    predictions = hypothesis(X, w)  # X має містити bias\n",
    "    errors = predictions - y\n",
    "    gradient = (1/m) * np.dot(X.T, errors)\n",
    "    \n",
    "    return w - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "fc3430f3-2f7d-40f8-b5f0-ef57792bb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y, learning_rate, iterations):\n",
    "    w = np.zeros(X.shape[1])  # ініціалізуємо ваги нулями\n",
    "\n",
    "    for i in range(iterations):\n",
    "        w = gradient_descent_step(X, y, w, learning_rate)\n",
    "        cost = compute_cost(X, y, w)\n",
    "        print(w)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "8810da88-02bc-4edc-8dbe-38ca103bf5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.67229201e+08 1.46390263e+05 6.61666767e+04]\n",
      "[-8.34523562e+13 -4.14599319e+10 -1.82670843e+10]\n",
      "[2.60612157e+19 1.29474706e+16 5.70460611e+15]\n",
      "[-8.13861939e+24 -4.04334689e+21 -1.78148320e+21]\n",
      "[2.54159769e+30 1.26269096e+27 5.56336813e+26]\n",
      "[-7.93711869e+35 -3.94323934e+32 -1.73737619e+32]\n",
      "[2.47867132e+41 1.23142852e+38 5.42562700e+37]\n",
      "[-7.74060686e+46 -3.84561032e+43 -1.69436122e+43]\n",
      "[2.41730293e+52 1.20094009e+49 5.29129615e+48]\n",
      "[-7.54896038e+57 -3.75039844e+54 -1.65241123e+54]\n",
      "[2.35745393e+63 1.17120651e+60 5.16029114e+59]\n",
      "[-7.36205880e+68 -3.65754388e+65 -1.61149986e+65]\n",
      "[2.29908670e+74 1.14220909e+71 5.03252963e+70]\n",
      "[-7.17978463e+79 -3.56698827e+76 -1.57160141e+76]\n",
      "[2.24216457e+85 1.11392961e+82 4.90793132e+81]\n",
      "[-7.00202332e+90 -3.47867469e+87 -1.53269078e+87]\n",
      "[2.18665174e+96 1.08635029e+93 4.78641788e+92]\n",
      "[-6.82866313e+101 -3.39254762e+098 -1.49474352e+098]\n",
      "[2.13251334e+107 1.05945379e+104 4.66791294e+103]\n",
      "[-6.65959509e+112 -3.30855294e+109 -1.45773579e+109]\n",
      "[2.07971533e+118 1.03322322e+115 4.55234202e+114]\n",
      "[-6.49471293e+123 -3.22663785e+120 -1.42164431e+120]\n",
      "[2.02822452e+129 1.00764207e+126 4.43963247e+125]\n",
      "[-6.33391303e+134 -3.14675086e+131 -1.38644641e+131]\n",
      "[1.97800855e+140 9.82694278e+136 4.32971345e+136]\n",
      "[-6.17709430e+145 -3.06884176e+142 -1.35211996e+142]\n",
      "[1.92903585e+151 9.58364158e+147 4.22251587e+147]\n",
      "[-6.02415818e+156 -2.99286158e+153 -1.31864338e+153]\n",
      "[1.88127565e+162 9.34636417e+158 4.11797235e+158]\n",
      "[-5.87500855e+167 -2.91876256e+164 -1.28599563e+164]\n",
      "[1.83469793e+173 9.11496141e+169 4.01601718e+169]\n",
      "[-5.72955165e+178 -2.84649813e+175 -1.25415620e+175]\n",
      "[1.78927340e+184 8.88928786e+180 3.91658627e+180]\n",
      "[-5.58769605e+189 -2.77602286e+186 -1.22310507e+186]\n",
      "[1.74497352e+195 8.66920167e+191 3.81961714e+191]\n",
      "[-5.44935260e+200 -2.70729246e+197 -1.19282272e+197]\n",
      "[1.70177045e+206 8.45456449e+202 3.72504882e+202]\n",
      "[-5.31443434e+211 -2.64026373e+208 -1.16329011e+208]\n",
      "[1.65963702e+217 8.24524144e+213 3.63282188e+213]\n",
      "[-5.18285646e+222 -2.57489453e+219 -1.13448869e+219]\n",
      "[1.61854675e+228 8.04110092e+224 3.54287835e+224]\n",
      "[-5.05453627e+233 -2.51114379e+230 -1.10640036e+230]\n",
      "[1.57847383e+239 7.84201464e+235 3.45516169e+235]\n",
      "[-4.92939310e+244 -2.44897142e+241 -1.07900745e+241]\n",
      "[1.53939305e+250 7.64785745e+246 3.36961678e+246]\n",
      "[-4.80734830e+255 -2.38833835e+252 -1.05229275e+252]\n",
      "[1.50127985e+261 7.45850731e+257 3.28618983e+257]\n",
      "[-4.68832515e+266 -2.32920647e+263 -1.02623947e+263]\n",
      "[1.46411029e+272 7.27384522e+268 3.20482842e+268]\n",
      "[-4.57224885e+277 -2.27153861e+274 -1.00083124e+274]\n",
      "[1.42786099e+283 7.09375510e+279 3.12548140e+279]\n",
      "[-4.45904644e+288 -2.21529853e+285 -9.76052069e+284]\n",
      "[1.39250917e+294 6.91812376e+290 3.04809890e+290]\n",
      "[-4.34864676e+299 -2.16045087e+296 -9.51886401e+295]\n",
      "[            inf 6.74684080e+301 2.97263228e+301]\n",
      "[ nan -inf -inf]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n",
      "[nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\4atty\\AppData\\Local\\Temp\\ipykernel_24648\\3435018892.py:4: RuntimeWarning: overflow encountered in square\n",
      "  cost = (1/(2*m)) * np.sum((predictions - y) ** 2)\n",
      "C:\\Users\\4atty\\AppData\\Local\\Temp\\ipykernel_24648\\3338230767.py:7: RuntimeWarning: invalid value encountered in subtract\n",
      "  return w - learning_rate * gradient\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[525], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Знаходимо найкращі параметри\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m w, cost_history \u001b[38;5;241m=\u001b[39m linear_regression(X, y, learning_rate, iterations)\n\u001b[0;32m      6\u001b[0m w\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# Знаходимо найкращі параметри\n",
    "w, cost_history = linear_regression(X, y, learning_rate, iterations)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "12ade5bc-37ac-49c1-906f-45b2cd551d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аналітичне рішення (Normal Equation) параметри: [3.72448352e+02 3.68974672e+05 1.37031315e+06]\n"
     ]
    }
   ],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "w_normal = normal_equation(X, y)\n",
    "print(f\"Аналітичне рішення (Normal Equation) параметри: {w_normal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "ee120f94-ff61-4df4-9f98-8248ec2b8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_regression(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "1bcd93e6-3cf6-4aba-af21-01bdb0e22165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.78762754e+02, 4.06820034e+05, 1.38604950e+06]), -173171.6076326361)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "63a18f07-554d-4114-b3db-1623f0f1b3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([821214.14349519, 299983.57107963, 695808.52272537])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "iterations = 100000\n",
    "\n",
    "# Навчання моделі\n",
    "w, cost_history = linear_regression(X_norm, y, learning_rate, iterations)\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "bffc0910-f93c-44a6-a7b4-b12f3879b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.sum((y_true - y_pred) ** 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "349cf3c1-4b0c-413f-ba5d-bbd2ea5efdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Градієнтний спуск\n",
    "def grad_descent(X, y, iter=3000, lr=0.001, stopping_threshold=0.001):\n",
    "    m, n = X.shape\n",
    "    w = np.random.rand(n) * 0.01\n",
    "    prev_cost = None\n",
    "\n",
    "    for i in range(iter):\n",
    "        y_pred = X.dot(w)\n",
    "        cost = mse(y, y_pred)\n",
    "        \n",
    "        if np.isnan(cost) or np.isinf(cost):\n",
    "            print(\"Cost is NaN or inf, exiting...\")\n",
    "            break\n",
    "            \n",
    "        if prev_cost is not None and abs(cost - prev_cost) <= stopping_threshold:\n",
    "            break\n",
    "\n",
    "        prev_cost = cost\n",
    "\n",
    "        gradient = (1/m) * (X.T.dot(y - y_pred))  # Градієнт\n",
    "        w -= lr * gradient  # Оновлення ваг\n",
    "\n",
    "        print(f'Iteration {i+1}: Cost {cost}, Weights: {w}')\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "9afa0dc3-61dd-4614-bc9a-126f9792d5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Cost 1.428652718584006e+16, Weights: [-2.67229076e+07 -1.46390132e+04 -6.61665892e+03]\n",
      "Iteration 2: Cost 1.21548428621042e+25, Weights: [-8.34581963e+11 -4.14631331e+08 -1.82685314e+08]\n",
      "Iteration 3: Cost 1.1854741238119855e+34, Weights: [-2.60639576e+16 -1.29488328e+13 -5.70520628e+12]\n",
      "Iteration 4: Cost 1.156204908926075e+43, Weights: [-8.13976235e+20 -4.04391473e+17 -1.78173338e+17]\n",
      "Iteration 5: Cost 1.1276583474687218e+52, Weights: [-2.54204416e+25 -1.26291277e+22 -5.56434541e+21]\n",
      "Iteration 6: Cost 1.099816597212866e+61, Weights: [-7.93879258e+29 -3.94407095e+26 -1.73774260e+26]\n",
      "Iteration 7: Cost 1.0726622564539109e+70, Weights: [-2.47928139e+34 -1.23173160e+31 -5.42696239e+30]\n",
      "Iteration 8: Cost 1.0461783531332721e+79, Weights: [-7.74278474e+38 -3.84669231e+35 -1.69483794e+35]\n",
      "Iteration 9: Cost 1.0203483342304706e+88, Weights: [-2.41806823e+43 -1.20132030e+40 -5.29297133e+39]\n",
      "Iteration 10: Cost 9.951560554171296e+96, Weights: [-7.55161631e+47 -3.75171794e+44 -1.65299259e+44]\n",
      "Iteration 11: Cost 9.70585770966418e+105, Weights: [-2.35836641e+52 -1.17165984e+49 -5.16228850e+48]\n",
      "Iteration 12: Cost 9.466221239116222e+114, Weights: [-7.36516780e+56 -3.65908847e+53 -1.61218040e+53]\n",
      "Iteration 13: Cost 9.232501364477094e+123, Weights: [-2.30013863e+61 -1.14273170e+58 -5.03483221e+57]\n",
      "Iteration 14: Cost 9.004552005698681e+132, Weights: [-7.18332269e+65 -3.56874601e+62 -1.57237586e+62]\n",
      "Iteration 15: Cost 8.78223068943185e+141, Weights: [-2.24334848e+70 -1.11451779e+67 -4.91052281e+66]\n",
      "Iteration 16: Cost 8.565398459977477e+150, Weights: [-7.00596730e+74 -3.48063409e+71 -1.53355409e+71]\n",
      "Iteration 17: Cost 8.35391979243611e+159, Weights: [-2.18796047e+79 -1.08700048e+76 -4.78928258e+75]\n",
      "Iteration 18: Cost 8.147662508001908e+168, Weights: [-6.83299081e+83 -3.39469765e+80 -1.49569082e+80]\n",
      "Iteration 19: Cost 7.9464976913479965e+177, Weights: [-2.13393999e+88 -1.06016257e+85 -4.67103577e+84]\n",
      "Iteration 20: Cost 7.750299610051583e+186, Weights: [-6.66428508e+92 -3.31088297e+89 -1.45876239e+89]\n",
      "Iteration 21: Cost 7.558945636008393e+195, Weights: [-2.08125326e+97 -1.03398728e+94 -4.55570845e+93]\n",
      "Iteration 22: Cost 7.372316168787449e+204, Weights: [-6.49974467e+101 -3.22913767e+098 -1.42274572e+098]\n",
      "Iteration 23: Cost 7.190294560878157e+213, Weights: [-2.02986737e+106 -1.00845826e+103 -4.44322855e+102]\n",
      "Iteration 24: Cost 7.012767044783073e+222, Weights: [-6.33926675e+110 -3.14941064e+107 -1.38761830e+107]\n",
      "Iteration 25: Cost 6.839622661910708e+231, Weights: [-1.97975018e+115 -9.83559541e+111 -4.33352577e+111]\n",
      "Iteration 26: Cost 6.670753193223967e+240, Weights: [-6.18275101e+119 -3.07165207e+116 -1.35335817e+116]\n",
      "Iteration 27: Cost 6.5060530916009016e+249, Weights: [-1.93087039e+124 -9.59275574e+120 -4.22653153e+120]\n",
      "Iteration 28: Cost 6.345419415865431e+258, Weights: [-6.03009962e+128 -2.99581335e+125 -1.31994392e+125]\n",
      "Iteration 29: Cost 6.188751766446832e+267, Weights: [-1.88319743e+133 -9.35591174e+129 -4.12217897e+129]\n",
      "Iteration 30: Cost 6.035952222627839e+276, Weights: [-5.88121718e+137 -2.92184707e+134 -1.28735466e+134]\n",
      "Iteration 31: Cost 5.886925281342025e+285, Weights: [-1.83670151e+142 -9.12491539e+138 -4.02040287e+138]\n",
      "Iteration 32: Cost 5.741577797482286e+294, Weights: [-5.73601063e+146 -2.84970701e+143 -1.25557002e+143]\n",
      "Iteration 33: Cost 5.599818925683124e+303, Weights: [-1.79135357e+151 -8.89962232e+147 -3.92113960e+147]\n",
      "Cost is NaN or inf, exiting...\n",
      "Отримані ваги: [-1.79135357e+151 -8.89962232e+147 -3.92113960e+147]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\4atty\\AppData\\Local\\Temp\\ipykernel_24648\\300550005.py:2: RuntimeWarning: overflow encountered in square\n",
      "  return np.mean(np.sum((y_true - y_pred) ** 2))\n"
     ]
    }
   ],
   "source": [
    "weights = grad_descent(X, y)\n",
    "print(\"Отримані ваги:\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "0703c3a5-1dd7-4736-8966-7ef481292459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN в X: False\n",
      "Безмежні в X: False\n",
      "NaN в y: False\n",
      "Безмежні в y: False\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN в X:\", np.isnan(X).any())\n",
    "print(\"Безмежні в X:\", np.isinf(X).any())\n",
    "print(\"NaN в y:\", np.isnan(y).any())\n",
    "print(\"Безмежні в y:\", np.isinf(y).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e35f1c-297d-4787-b0b2-813e16b943bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
